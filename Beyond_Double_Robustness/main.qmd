---
title: "Beyond Double Robustness"
author: "Mingcheng Hu"
---

```{r}
library(knitr)
library(knitrProgressBar)

set.seed(1234)
```

We use the numerical implementation/simulation in the paper Estimation with Missing Data: Beyond Double Robustness and compare the RMSE of five methods.

# Estimation with Missing Data

```{r}
expit = function(x) 1/(1+exp(-x))
logit = function(p) log(p/(1-p))


data.gen <- function(N) {
    x = runif(N, -2.5, 2.5)
    y = rnorm(1 + 2*x + 3*x^2, 4*x^2+2)
    D = rbinom(N, 1, expit(1 + 2*x + 3*x^2))

    n = sum(D)

    return(list(y=y, D=D, x=x, n=n, N=N))
}
```


```{r}
simu <- function(N, nrep = 2000) {
    result = NULL
    pb = progress_estimated(nrep)
    for (i in 1:nrep) {
        update_progress(pb)
        dat = data.gen(N)
        N = dat$N
        n = dat$n
        y = dat$y
        D = dat$D
        x = dat$x

        # Y_mean = mean(y)
        tryCatch({
            x0 = rep(x, D)
            y0 = rep(y, D)

            model = glm(D~x+I(x^2), family=binomial(link="logit")) # correct propensity score model
            ex = model$fitted.values

            alpha_hat = mean(ex)
            ex0 = rep(ex, D)
            gi = rep(ex - alpha_hat, D)

            # Method 1: Section 2  (Beyond Double Robustness)
            fn_rho = function(rho) sum( gi  /  (1 + rho*gi) ) / n
            rho_values = seq(-50, 50, 0.005)
            fn_rho_values = sapply(rho_values, fn_rho)
            # plot(rho_values, fn_rho_values, type="p", xlab="rho", ylab="f_n(rho)/n", ylim=c(-0.2,0.2))
            rho = uniroot(fn_rho, c(-3, 3))$root
            # print(c(1/alpha_hat, rho))

            wi = 1/(n * (1 + rho*gi))  # sum is 1
            Y_hat1 = sum(y0*wi)

            # Method 2: Section 3 (Beyond Double Robustness)
            fn_lambda <- function(lam) sum( (gi/ex0)  /  (1 + lam*gi/ex0)  ) / n
            lambda_values = seq(-50, 50, 0.005)
            fn_lambda_values = sapply(lambda_values, fn_lambda)
            # plot(lambda_values, fn_lambda_values, type="p", xlab="lambda", ylab="f_n(lambda)/n", ylim=c(-0.2,0.2))

            lambda = uniroot(fn_lambda, interval=c(-2,2))$root
            tmp = 1 + lambda*gi/ex0
            prob.el = 1/(n*tmp)   # sum is not 1
            wi = prob.el*alpha_hat/ex0  # sum is 1

            Y_hat2 = sum(y0*wi)

            # Method 3: Biased-Sample EL
            eeps =sqrt(.Machine$double.eps)    # root of machine precision

            low = min(ex0);   
            xi  = n/N + (1-n/N)*ex0
            up  = min(xi)-eeps    

            # print(c(low, up))

            fun_alpha <- function(alpha){  sum((ex0-alpha)/(xi-alpha)) }
            alpha   <- uniroot(fun_alpha, interval=c(low, up), tol=eeps)$root
            lambda  =  (N/n-1)/(1-alpha)      
            tmp     =  1+lambda*(ex0-alpha) 
            prob.el =  1/(n*tmp) 

            Y_hat3 = sum(y0*prob.el)

            # Method 4: IPW
            Y_hat4 = sum(D*y/ex)/length(y0)


            # Method 5: Stablized IPW

            Y_hat5 = sum(D*y/ex)/sum(D/ex)



            # Return all values

            result = rbind(result, c(Y_hat1, Y_hat2, Y_hat3, Y_hat4, Y_hat5))
        }, error = function(e) {
            print(paste("Error in iteration", i, ":", e))
            result = result
        })

    }
    return(result)
}
```


```{r label = "Simulation", cache = TRUE}
N_large=100000
N_normal=4000

dat_large = data.gen(N_large)
Y_true = mean(dat_large$y)

result = simu(N_normal)
save(result, file="result.RData")
```

```{r}
load("result.RData")
rmse = sqrt(apply( (result - Y_true)^2, 2, mean))
rmse = sqrt(N_normal) * rmse
rmse
```


